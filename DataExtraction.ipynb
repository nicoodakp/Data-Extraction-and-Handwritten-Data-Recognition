{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataExtraction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronak0001/Data-Extraction-and-Handwritten-Data-Recognition/blob/master/DataExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJlgI4cXVqpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytesseract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEGvgsHLXE_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WpvdYf8WQ4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract as pyt\n",
        "\n",
        "# reading an image file\n",
        "img = cv2.imread('image_path/image_name.jpg')\n",
        "\n",
        "# converting rgb image to gray-scale image\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# applying threshold to gray-scale image\n",
        "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# writing manipulated images\n",
        "# cv2.imwrite('grayTemp.jpg', gray)\n",
        "# cv2.imwrite('binTemp.jpg', thresh)\n",
        "\n",
        "# performing image dilation to brighten text from image\n",
        "kernel = np.ones((5, 25), np.uint8)\n",
        "img_dil = cv2.dilate(thresh, kernel, iterations=1)\n",
        "# cv2.imwrite('imgDilation.jpg', img_dil)\n",
        "\n",
        "# finding contours\n",
        "_,ctrs, hier = cv2.findContours(img_dil, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
        "# sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "reconText = []\n",
        "\n",
        "for i, ctr in enumerate(ctrs):\n",
        "    # considering only child contours\n",
        "    if hier[0][i][2] != -1:\n",
        "        continue\n",
        "    x, y, z, w = cv2.boundingRect(ctr)\n",
        "    # cropping and recognizing text\n",
        "    cropped = img[y:y+w,x:x+z]\n",
        "#    cv2.imwrite('cropped.jpg', cropped)\n",
        "    temp = pyt.image_to_string(cropped)\n",
        "    if temp != '':\n",
        "        reconText.append(temp)\n",
        "    cv2.rectangle(img, (x,y), (x+z, y+w), (0, 0, 255), 1)\n",
        "\n",
        "\n",
        "# Dict = {}\n",
        "keyLen = np.array(reconText).shape[0]\n",
        "for i in range(0,keyLen):\n",
        "    print((reconText[keyLen-i-1].split(':')[0]))\n",
        "#    Dict[(reconText[keyLen-i-1].split(':')[0])]=''\n",
        "\n",
        "# f = open(\"dict.txt\",\"w\")\n",
        "# f.write(str(Dict))\n",
        "# f.close()\n",
        "cv2.imwrite('detectedCont.jpg', img)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}